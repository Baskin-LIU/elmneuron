{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9494ea3-a5b5-4814-bcb0-7128fcc18432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "package_path = Path(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "sys.path.insert(0, str(package_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807bd9d9-7cae-473b-95e8-20f99ecb6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neuronio.neuronio_data_utils import (\n",
    "    DEFAULT_Y_SOMA_THRESHOLD,\n",
    "    DEFAULT_Y_TRAIN_SOMA_BIAS,\n",
    "    DEFAULT_Y_TRAIN_SOMA_SCALE,\n",
    "    NEURONIO_DATA_DIM,\n",
    "    NEURONIO_LABEL_DIM,\n",
    "    NEURONIO_SIM_LEN,\n",
    "    NEURONIO_SIM_PER_FILE,\n",
    "    create_neuronio_input_type,\n",
    "    parse_sim_experiment_file,\n",
    "    get_data_files_from_folder, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db60459a-e66b-42c2-afae-758748d323fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# General Config\n",
    "general_config = dict()\n",
    "general_config[\"seed\"] = 0\n",
    "general_config[\"device\"] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "general_config[\"train_valid_eval\"] = False\n",
    "general_config[\"artefacts_dir\"]= \"../models/new_exp/forget_True_rest_True_nummem_10\"\n",
    "torch_device = torch.device(general_config[\"device\"])\n",
    "print(\"Torch Device: \", torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc83f52-2eea-40d6-a8c0-a037e3836e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding & Determinism\n",
    "os.environ['PYTHONHASHSEED'] = str(general_config[\"seed\"])\n",
    "random.seed(general_config[\"seed\"])\n",
    "np.random.seed(general_config[\"seed\"])\n",
    "torch.manual_seed(general_config[\"seed\"])\n",
    "torch.cuda.manual_seed(general_config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd6b2a0-067c-4f12-9c1c-bf498144e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = Path(\"D:/NeuronIO\").expanduser().resolve() # TODO: change to neuronio data path\n",
    "train_data_dir_path = data_dir_path / \"train\"  # TODO: change to train subfolder\n",
    "test_data_dir_path = data_dir_path / \"test/Data_test\"  # TODO: change to test subfolder\n",
    "\n",
    "data_config = dict()\n",
    "train_data_dirs = [\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_1\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_2\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_3\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_4\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_5\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_6\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_7\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_8\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_9\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_10\"),\n",
    "]\n",
    "test_data_dirs = [str(test_data_dir_path)]\n",
    "\n",
    "data_config[\"train_data_dirs\"] = train_data_dirs\n",
    "data_config[\"test_data_dirs\"] = test_data_dirs\n",
    "\n",
    "data_config[\"data_dim\"] = NEURONIO_DATA_DIM \n",
    "data_config[\"label_dim\"] = NEURONIO_LABEL_DIM\n",
    "\n",
    "train_files = get_data_files_from_folder(data_config[\"train_data_dirs\"])\n",
    "test_files = get_data_files_from_folder(data_config[\"test_data_dirs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae3e36-bc58-4201-9a93-ef844db0201b",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25af67a5-518a-4d57-8a88-87cddeba9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.expressive_leaky_memory_neuron import ELM\n",
    "from src.expressive_leaky_memory_neuron_forget import ELMf\n",
    "from src.neuronio.neuronio_data_utils import (\n",
    "    NEURONIO_DATA_DIM, \n",
    "    NEURONIO_LABEL_DIM, \n",
    "    get_data_files_from_folder, \n",
    "    parse_sim_experiment_file,\n",
    "    visualize_training_batch,\n",
    ")\n",
    "from src.neuronio.neuronio_data_loader_filtered import NeuronIO\n",
    "from src.neuronio.neuronio_train_utils import NeuronioLoss\n",
    "from src.neuronio.neuronio_eval_utils_filtered import (\n",
    "    NeuronioEvaluator, \n",
    "    compute_test_predictions_multiple_sim_files, \n",
    "    filter_and_extract_core_results,\n",
    ")\n",
    "from src.neuronio.neuronio_data_utils import parse_sim_experiment_file, create_neuronio_input_type, DEFAULT_Y_SOMA_THRESHOLD\n",
    "from src.neuronio.neuronio_viz_utils import visualize_neuron_workings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c19d15-702a-4e20-b03b-ad7c0ee07ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model config\n",
    "with open(general_config[\"artefacts_dir\"] + \"/model_config.json\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "# load train config\n",
    "with open(general_config[\"artefacts_dir\"] + \"/train_config.json\") as f:\n",
    "    train_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc7f5af-f2b6-4758-8611-58ba4ac62463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "ELMf(\n",
      "  (mlp): RecursiveScriptModule(\n",
      "    original_name=MLP\n",
      "    (network): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(original_name=Linear)\n",
      "      (1): RecursiveScriptModule(original_name=ReLU)\n",
      "      (2): RecursiveScriptModule(original_name=Linear)\n",
      "    )\n",
      "  )\n",
      "  (mlpf): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Linear)\n",
      "    (1): RecursiveScriptModule(original_name=Sigmoid)\n",
      "  )\n",
      "  (w_y): RecursiveScriptModule(original_name=Linear)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bingkun LIU\\AppData\\Local\\Temp\\ipykernel_32508\\3546985411.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(general_config[\"artefacts_dir\"] + \"/neuronio_best_model_state.pt\", map_location=torch_device)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ELM model\n",
    "if train_config['forget_gate']:\n",
    "    model = ELMf(**model_config).to(torch_device)\n",
    "else:\n",
    "    model = ELM(**model_config).to(torch_device)\n",
    "\n",
    "\n",
    "# Load the best model for evaluation\n",
    "state_dict = torch.load(general_config[\"artefacts_dir\"] + \"/neuronio_best_model_state.pt\", map_location=torch_device)\n",
    "print(model.load_state_dict(state_dict))\n",
    "# Visualize ELM model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5677cda7-26e7-4a37-a127-f59c16cb6cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# load file\u001b[39;00m\n\u001b[0;32m      8\u001b[0m select_test_file \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m test_files \u001b[38;5;28;01mif\u001b[39;00m sample_file_name \u001b[38;5;129;01min\u001b[39;00m file][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m viz_X, viz_y_spike, viz_y_soma \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sim_experiment_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect_test_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# select sequence\u001b[39;00m\n\u001b[0;32m     12\u001b[0m viz_X \u001b[38;5;241m=\u001b[39m viz_X[:, sample_select_start: sample_select_start\u001b[38;5;241m+\u001b[39msample_select_len, sample_sequence_index]\n",
      "File \u001b[1;32m~\\elmneuron\\src\\neuronio\\neuronio_data_utils.py:306\u001b[0m, in \u001b[0;36mparse_sim_experiment_file\u001b[1;34m(sim_experiment_file, include_params, verbose, encoding)\u001b[0m\n\u001b[0;32m    304\u001b[0m X_ex \u001b[38;5;241m=\u001b[39m dict2bin(sim_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexInputSpikeTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_segments, sim_duration_ms)\n\u001b[0;32m    305\u001b[0m X_inh \u001b[38;5;241m=\u001b[39m dict2bin(sim_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minhInputSpikeTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_segments, sim_duration_ms)\n\u001b[1;32m--> 306\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((X_ex, X_inh))\n\u001b[0;32m    307\u001b[0m spike_times \u001b[38;5;241m=\u001b[39m (sim_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputSpikeTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    308\u001b[0m y_spike[spike_times, k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# apples to apples comparison\n",
    "sample_file_name = \"100523.p\"\n",
    "sample_sequence_index = 33\n",
    "sample_select_start = 2000\n",
    "sample_select_len = 2000\n",
    "\n",
    "# load file\n",
    "select_test_file = [file for file in test_files if sample_file_name in file][0]\n",
    "viz_X, viz_y_spike, viz_y_soma = parse_sim_experiment_file(select_test_file)\n",
    "\n",
    "# select sequence\n",
    "viz_X = viz_X[:, sample_select_start: sample_select_start+sample_select_len, sample_sequence_index]\n",
    "viz_y_spike = viz_y_spike[sample_select_start: sample_select_start+sample_select_len, sample_sequence_index]\n",
    "viz_y_soma = viz_y_soma[sample_select_start: sample_select_start+sample_select_len, sample_sequence_index]\n",
    "\n",
    "# preprocess sequence\n",
    "synapse_types = create_neuronio_input_type()\n",
    "viz_X = torch.tensor(viz_X.T * synapse_types[:]).to(torch_device)\n",
    "viz_y_soma = np.clip(viz_y_soma, a_min=None, a_max=DEFAULT_Y_SOMA_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65a2e972-74df-47f6-9b36-db991e20cb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualize_neuron_workings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_spikes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviz_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_spikes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviz_y_spike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_soma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviz_y_soma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_by_memory_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\elmneuron\\src\\neuronio\\neuronio_viz_utils.py:35\u001b[0m, in \u001b[0;36mvisualize_neuron_workings\u001b[1;34m(neuron, input_spikes, target_spikes, target_soma, burn_in_time, syn_sample_values, mem_sample_values, color_by_memory_tau, y_train_soma_bias, y_soma_threshold, save_fig_path, seed, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Make copy of inputs\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m input_spikes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_spikes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m target_soma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(target_soma)\n\u001b[0;32m     37\u001b[0m target_spikes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(target_spikes)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\elm\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:965\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(a, order, subok)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_copy_dispatcher)\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(a, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m    Return an array copy of the given object.\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03m    array([3, 2, 3])\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\elm\\lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "visualize_neuron_workings(\n",
    "    neuron=model,\n",
    "    input_spikes=viz_X,\n",
    "    target_spikes=viz_y_spike,\n",
    "    target_soma=viz_y_soma,\n",
    "    color_by_memory_tau=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d15685-c63a-4a59-99d0-7add8625747b",
   "metadata": {},
   "source": [
    "## Evaluation with different burn-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f42405-f49e-46ed-add0-48f456ff2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in_times = np.arange(0, 151, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0417510-4c42-442c-9b4e-421ffb012e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gather all evaluation metrics\n",
    "# set burn-in in\n",
    "eval_results_full = {}\n",
    "with torch.no_grad():\n",
    "    for burn_in_time in burn_in_times:\n",
    "        if general_config[\"train_valid_eval\"]:\n",
    "            random.seed(general_config[\"seed\"])\n",
    "            select_train_files = random.choices(train_files, k=10)\n",
    "            train_predictions = compute_test_predictions_multiple_sim_files(\n",
    "                neuron=model,\n",
    "                test_files=select_train_files,\n",
    "                input_window_size=train_config[\"input_window_size\"],\n",
    "                rest_start = train_config['rest_start'],\n",
    "                device=torch_device,\n",
    "            )\n",
    "            train_results = filter_and_extract_core_results(*train_predictions, burn_in_times=burn_in_times, verbose=False)\n",
    "    \n",
    "            valid_predictions = compute_test_predictions_multiple_sim_files(\n",
    "                neuron=model,\n",
    "                test_files=valid_files,\n",
    "                input_window_size=train_config[\"input_window_size\"],\n",
    "                rest_start = train_config['rest_start'],\n",
    "                device=torch_device,\n",
    "            )\n",
    "            valid_results = filter_and_extract_core_results(*valid_predictions, burn_in_times=burn_in_times, verbose=False)\n",
    "    \n",
    "    \n",
    "        test_predictions = compute_test_predictions_multiple_sim_files(\n",
    "            neuron=model,\n",
    "            test_files=test_files,\n",
    "            burn_in_time=burn_in_time,\n",
    "            input_window_size=train_config[\"input_window_size\"],\n",
    "            rest_start = True, #train_config['rest_start'],\n",
    "            device=torch_device,\n",
    "        )\n",
    "        test_results = filter_and_extract_core_results(*test_predictions, verbose=False)\n",
    "    \n",
    "        eval_results = dict()\n",
    "        if general_config[\"train_valid_eval\"]:\n",
    "            eval_results[\"train_results\"] = train_results\n",
    "            eval_results[\"valid_results\"] = valid_results\n",
    "        eval_results[\"test_results\"] = test_results\n",
    "        eval_results_full[burn_in_time] = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1173a826-6ee3-492f-a2ef-9aeb22587d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): {'test_results': {'TP @ 0.0025 FP': np.float64(0.020257826887661142),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.001448741559238797),\n",
       "   'TP @ 0.0100 FP': np.float64(0.30033763044812767),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.12591620626151012),\n",
       "   'AUC': np.float64(0.9443477803277374),\n",
       "   'soma_explained_variance_percent': 56.355741532743544,\n",
       "   'soma_RMSE': np.float64(2.025873361261238),\n",
       "   'soma_MAE': 1.451216855160072}},\n",
       " np.int64(25): {'test_results': {'TP @ 0.0025 FP': np.float64(0.15224063842848373),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.07967771639042356),\n",
       "   'TP @ 0.0100 FP': np.float64(0.39103744628606507),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.23579248525808733),\n",
       "   'AUC': np.float64(0.9488942132092616),\n",
       "   'soma_explained_variance_percent': 62.476497053999935,\n",
       "   'soma_RMSE': np.float64(1.878322644566575),\n",
       "   'soma_MAE': 1.3689848093914463}},\n",
       " np.int64(50): {'test_results': {'TP @ 0.0025 FP': np.float64(0.15669122160834867),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.08268569674647024),\n",
       "   'TP @ 0.0100 FP': np.float64(0.3927255985267035),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.23686504091932647),\n",
       "   'AUC': np.float64(0.9493989990515093),\n",
       "   'soma_explained_variance_percent': 63.33460023140876,\n",
       "   'soma_RMSE': np.float64(1.856690555548255),\n",
       "   'soma_MAE': 1.3479342068549214}},\n",
       " np.int64(75): {'test_results': {'TP @ 0.0025 FP': np.float64(0.15500306936771024),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.08322590546347453),\n",
       "   'TP @ 0.0100 FP': np.float64(0.39825046040515655),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.239805692824543),\n",
       "   'AUC': np.float64(0.9497610105262921),\n",
       "   'soma_explained_variance_percent': 64.3414909716796,\n",
       "   'soma_RMSE': np.float64(1.831001058427213),\n",
       "   'soma_MAE': 1.3249747914021517}},\n",
       " np.int64(100): {'test_results': {'TP @ 0.0025 FP': np.float64(0.15653775322283608),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.08404693300963391),\n",
       "   'TP @ 0.0100 FP': np.float64(0.4016267648864334),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.24108507313026792),\n",
       "   'AUC': np.float64(0.9503104384036087),\n",
       "   'soma_explained_variance_percent': 65.12347296172425,\n",
       "   'soma_RMSE': np.float64(1.8108051536988283),\n",
       "   'soma_MAE': 1.309054575792354}},\n",
       " np.int64(125): {'test_results': {'TP @ 0.0025 FP': np.float64(0.15469613259668508),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.08267034990791897),\n",
       "   'TP @ 0.0100 FP': np.float64(0.40239410681399634),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.24180763139599584),\n",
       "   'AUC': np.float64(0.9503997076752508),\n",
       "   'soma_explained_variance_percent': 65.63154042966677,\n",
       "   'soma_RMSE': np.float64(1.7975641486288048),\n",
       "   'soma_MAE': 1.297704008119205}},\n",
       " np.int64(150): {'test_results': {'TP @ 0.0025 FP': np.float64(0.15822590546347454),\n",
       "   'AUC @ 0.0025 FP': np.float64(0.08356660527931245),\n",
       "   'TP @ 0.0100 FP': np.float64(0.40331491712707185),\n",
       "   'AUC @ 0.0100 FP': np.float64(0.2427358092121917),\n",
       "   'AUC': np.float64(0.950818412308037),\n",
       "   'soma_explained_variance_percent': 65.98946433698887,\n",
       "   'soma_RMSE': np.float64(1.788178792227469),\n",
       "   'soma_MAE': 1.2896371607530126}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7f0bb-159a-4f9d-b538-d5e73b4b4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show evaluation results\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09350d52-4566-47ea-b69f-b032cc31720f",
   "metadata": {},
   "source": [
    "## Preprocess starting points NeuronIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12cd7446-fda4-473a-bf52-aa56e67f9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_time_from_start = 500\n",
    "threshold = -65\n",
    "threshold_h = -60\n",
    "section_len = 200\n",
    "start_point_persec = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32a4d83-0463-4b5d-bbcd-49a238719b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../data_processed/NeuronIOstartpoint/'\n",
    "burn_in_times = np.arange(0, 151, 25)\n",
    "for file_path in test_files:\n",
    "    X, y_spike, y_soma = parse_sim_experiment_file(\n",
    "        sim_experiment_file=file_path,\n",
    "        include_params=False,\n",
    "        )\n",
    "    sim_len, sim_num = y_soma.shape\n",
    "    num_sec = int(sim_len/section_len)\n",
    "    sections = y_soma.T.reshape([sim_num,num_sec,section_len])\n",
    "    start_time  = np.ones([sim_num, num_sec, start_point_persec], dtype=int)\n",
    "    \n",
    "    recover_points_sim = {k: [] for k in burn_in_times}\n",
    "    \n",
    "    for sim in range(sim_num):\n",
    "        full_choice  = []\n",
    "        for i in range(num_sec):\n",
    "            choice = (sections[sim, i, :] < threshold).nonzero()[0] + i * section_len\n",
    "            if len(choice) < start_point_persec:\n",
    "                choice = (sections[sim, i, :] < threshold_h).nonzero()[0] + i * section_len\n",
    "\n",
    "            full_choice.append(np.sort(choice))\n",
    "            \n",
    "            # try:\n",
    "            #     start_time[sim, i, :] = np.random.choice(choice, start_point_persec, replace=False)\n",
    "            # except:\n",
    "            #     start_time[sim, i, :choice.shape[0]] = choice\n",
    "            #     start_time[sim, i, choice.shape[0]:] = np.random.choice(choice, start_point_persec-choice.shape[0], replace=False)\n",
    "                \n",
    "        full_choice = np.hstack(full_choice)\n",
    "        recover_points = {k: [0] for k in burn_in_times}\n",
    "        burn_in = 150\n",
    "        for t_next in full_choice:\n",
    "            for burn_in in burn_in_times:\n",
    "                if recover_points[burn_in][-1]>= 5500:\n",
    "                    continue \n",
    "                if t_next - recover_points[burn_in][-1] > 500-burn_in:\n",
    "                    recover_points[burn_in].append(t_last)                          \n",
    "            t_last = t_next\n",
    "\n",
    "        for burn_in in burn_in_times:\n",
    "            recover_points_sim[burn_in].append(np.array(recover_points[burn_in]))\n",
    "            \n",
    "    #pad and stack with -1\n",
    "    for burn_in in burn_in_times:\n",
    "        max_length = max(len(arr) for arr in recover_points_sim[burn_in])\n",
    "        # Pad each array with zeros to the maximum length\n",
    "        padded = [np.pad(arr, (0, max_length - len(arr)), mode='constant', constant_values = -1) for arr in recover_points_sim[burn_in]]\n",
    "        recover_points_sim[burn_in] = np.vstack(padded)\n",
    "    \n",
    "    #start_time = np.sort(start_time.reshape([sim_num, -1]), axis=1)\n",
    "    #np.save(save_path + file_path[-92:-2]+'.npy', start_time, allow_pickle=True)\n",
    "    with open(save_path + file_path[-92:-2]+'_recover.pkl', 'wb') as fp:\n",
    "        pickle.dump(recover_points_sim, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8762e847-f8b6-4ec0-a4ca-6cdadd822afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.125\n",
      "-60.15625\n",
      "-65.1875\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.40625\n",
      "-65.125\n",
      "-60.09375\n",
      "-65.125\n",
      "-65.0625\n",
      "-65.375\n",
      "-65.0625\n",
      "-65.5\n",
      "-65.0625\n",
      "-60.0625\n",
      "-65.0625\n",
      "-65.1875\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.03125\n",
      "-65.375\n",
      "-65.125\n",
      "-60.5\n",
      "-60.03125\n",
      "-65.25\n",
      "-60.03125\n",
      "-60.0625\n",
      "-65.3125\n",
      "-65.0625\n",
      "-60.03125\n",
      "-60.0625\n",
      "-60.125\n",
      "-65.125\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.0625\n",
      "-60.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.1875\n",
      "-65.9375\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.28125\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.15625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.125\n",
      "-65.0625\n",
      "-65.1875\n",
      "-65.8125\n",
      "-65.1875\n",
      "-60.375\n",
      "-60.03125\n",
      "-65.125\n",
      "-65.3125\n",
      "-65.1875\n",
      "-60.0625\n",
      "-65.0625\n",
      "-60.03125\n",
      "-65.5\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.9375\n",
      "-60.15625\n",
      "-65.125\n",
      "-65.125\n",
      "-60.0625\n",
      "-60.625\n",
      "-60.125\n",
      "-60.5\n",
      "-60.03125\n",
      "-65.4375\n",
      "-65.0625\n",
      "-60.125\n",
      "-60.125\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.375\n",
      "-65.1875\n",
      "-65.0625\n",
      "-60.03125\n",
      "-69.5\n",
      "-60.03125\n",
      "-60.4375\n",
      "-65.0625\n",
      "-60.5\n",
      "-65.125\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.03125\n",
      "-60.0625\n",
      "-65.3125\n",
      "-65.0625\n",
      "-60.1875\n",
      "-60.09375\n",
      "-60.5\n",
      "-65.0625\n",
      "-60.96875\n",
      "-60.53125\n",
      "-65.0625\n",
      "-68.125\n",
      "-65.0625\n",
      "-65.3125\n",
      "-65.0625\n",
      "-65.0625\n",
      "-60.03125\n",
      "-65.0625\n",
      "-60.03125\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n",
      "-65.0625\n"
     ]
    }
   ],
   "source": [
    "for sim in range(sim_num):\n",
    "    print(y_soma[start_time[sim], sim].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4e6797-bab4-4d0e-9aad-458bdb8ca4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../data_processed/NeuronIOstartpoint/'\n",
    "file_path = test_files[2]\n",
    "start_time = np.load(save_path + file_path[-92:-2]+'.npy')\n",
    "with open(save_path + file_path[-92:-2]+'_recover.pkl', 'rb') as fp:\n",
    "    recover_points_sim = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d062635-7161-41b9-a0d6-9a59e98b7a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  375,  750, ..., 5217, 5592,   -1],\n",
       "       [   0,  375,  750, ..., 5162, 5537,   -1],\n",
       "       [   0,  375,  714, ..., 4983, 5358, 5733],\n",
       "       ...,\n",
       "       [   0,  375,  750, ..., 5250, 5625,   -1],\n",
       "       [   0,  316,  691, ..., 5182, 5557,   -1],\n",
       "       [   0,  375,  676, ..., 5110, 5438, 5813]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recover_points_sim[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "201f2c19-2d1a-4d43-832f-eb2bf8d4a49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  15,   17,   19, ..., 5962, 5979, 5989],\n",
       "       [   3,   65,   69, ..., 5985, 5986, 5998],\n",
       "       [   7,    8,   41, ..., 5981, 5991, 5998],\n",
       "       ...,\n",
       "       [   0,    2,    3, ..., 5939, 5985, 5987],\n",
       "       [  10,   28,   42, ..., 5984, 5985, 5997],\n",
       "       [   6,   12,   19, ..., 5968, 5981, 5993]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0973e79-42f4-44b1-a336-c6d5cc71733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(379)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(sec_ealiest, axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6864197a-b5ef-4437-8f8a-c90443ef559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_start = np.sort(start_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7647f836-5977-4260-9274-2023332602d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    2,    9, ..., 5963, 5968, 5976],\n",
       "       [   2,   14,   23, ..., 5932, 5934, 5936],\n",
       "       [  10,   12,   31, ..., 5986, 5991, 5992],\n",
       "       ...,\n",
       "       [   8,   10,   21, ..., 5982, 5983, 5987],\n",
       "       [   0,   25,   29, ..., 5981, 5988, 5993],\n",
       "       [   4,   15,   23, ..., 5971, 5980, 5982]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6eb4def-51e8-43e6-938f-4117ed3f3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = np.diff(sort_start[:, np.arange(0, start_time.shape[1], start_point_persec)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee07d44d-fc23-4205-8b5f-2de35019d98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(358)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be344c8e-00b3-4155-a1c7-8f24ebdcd00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "20\n",
      "17\n",
      "21\n",
      "22\n",
      "22\n",
      "23\n",
      "21\n",
      "23\n",
      "17\n",
      "20\n",
      "22\n",
      "25\n",
      "22\n",
      "25\n",
      "21\n",
      "25\n",
      "26\n",
      "24\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "23\n",
      "18\n",
      "27\n",
      "19\n",
      "25\n",
      "27\n",
      "27\n",
      "24\n",
      "26\n",
      "22\n",
      "27\n",
      "21\n",
      "23\n",
      "23\n",
      "24\n",
      "25\n",
      "29\n",
      "33\n",
      "26\n",
      "25\n",
      "25\n",
      "22\n",
      "31\n",
      "27\n",
      "26\n",
      "26\n",
      "27\n",
      "24\n",
      "25\n",
      "25\n",
      "28\n",
      "26\n",
      "28\n",
      "28\n",
      "32\n",
      "28\n",
      "32\n",
      "28\n",
      "33\n",
      "28\n",
      "34\n",
      "36\n",
      "31\n",
      "28\n",
      "33\n",
      "37\n",
      "36\n",
      "27\n",
      "26\n",
      "25\n",
      "23\n",
      "26\n",
      "28\n",
      "26\n",
      "26\n",
      "22\n",
      "24\n",
      "28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m train_files:\n\u001b[1;32m----> 2\u001b[0m     X, y_spike, y_soma \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sim_experiment_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43msim_experiment_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     sim_len, sim_num \u001b[38;5;241m=\u001b[39m y_soma\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#print(y_spike.sum(axis=0))\u001b[39;00m\n",
      "File \u001b[1;32m~\\elmneuron\\src\\neuronio\\neuronio_data_utils.py:306\u001b[0m, in \u001b[0;36mparse_sim_experiment_file\u001b[1;34m(sim_experiment_file, include_params, verbose, encoding)\u001b[0m\n\u001b[0;32m    304\u001b[0m X_ex \u001b[38;5;241m=\u001b[39m dict2bin(sim_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexInputSpikeTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_segments, sim_duration_ms)\n\u001b[0;32m    305\u001b[0m X_inh \u001b[38;5;241m=\u001b[39m dict2bin(sim_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minhInputSpikeTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_segments, sim_duration_ms)\n\u001b[1;32m--> 306\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((X_ex, X_inh))\n\u001b[0;32m    307\u001b[0m spike_times \u001b[38;5;241m=\u001b[39m (sim_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputSpikeTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    308\u001b[0m y_spike[spike_times, k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_path in train_files:\n",
    "    X, y_spike, y_soma = parse_sim_experiment_file(\n",
    "        sim_experiment_file=file_path,\n",
    "        include_params=False,\n",
    "        )\n",
    "    sim_len, sim_num = y_soma.shape\n",
    "    #print(y_spike.sum(axis=0))\n",
    "    print(np.sum(y_spike.sum(axis=0) > 10))\n",
    "    #print(len(np.nonzero(y_spike.sum(axis=0) > 10)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174a230c-2dd7-46d8-8c73-e9625e535799",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_spike, y_soma = parse_sim_experiment_file(\n",
    "        sim_experiment_file=test_files[0],\n",
    "        include_params=False,\n",
    "        )\n",
    "sim_len, sim_num = y_soma.shape\n",
    "qualified = np.nonzero(y_spike.sum(axis=0) > 10)[0]\n",
    "    #print(y_spike.sum(axis=0))\n",
    "#print(np.sum(y_spike.sum(axis=0) > 10))\n",
    "    #print(len(np.nonzero(y_spike.sum(axis=0) > 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "838e0948-483a-47e9-a789-eab7c406e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   5,   9,  10,  11,  17,  21,  24,  27,  34,  40,  45,  54,\n",
       "        66,  68,  72,  73,  76,  91,  97, 111, 114])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f479f0-9b3c-430e-b130-0a13c87a9b3c",
   "metadata": {},
   "source": [
    "## Generating Random Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e54899-b78c-488b-aa55-a8c3117b1913",
   "metadata": {},
   "source": [
    "## Generating Output from random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cef91e-5453-4bd0-b740-bd1e568d561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neuronio.neuronio_eval_utils import (\n",
    "    NeuronioEvaluator, \n",
    "    compute_test_predictions_multiple_sim_files, \n",
    "    filter_and_extract_core_results,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predictions = compute_test_predictions_multiple_sim_files(\n",
    "        neuron=model,\n",
    "        test_files=test_files,\n",
    "        burn_in_time=train_config[\"burn_in_time\"],\n",
    "        input_window_size=train_config[\"input_window_size\"],\n",
    "        device=torch_device,\n",
    "    )\n",
    "    test_results = filter_and_extract_core_results(*test_predictions, verbose=False)\n",
    "\n",
    "eval_results = dict()\n",
    "if general_config[\"train_valid_eval\"]:\n",
    "    eval_results[\"train_results\"] = train_results\n",
    "    eval_results[\"valid_results\"] = valid_results\n",
    "eval_results[\"test_results\"] = test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
