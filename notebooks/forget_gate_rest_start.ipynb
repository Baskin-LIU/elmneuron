{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c730d809-4b95-4fa4-945d-09103a1bbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: reduced implementation might require slightly different parameters for same results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc32956-961d-4a6e-b21e-e95ef41bf99d",
   "metadata": {},
   "source": [
    "## Notebook Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182c286f-8a28-4500-a9ee-ec48956e6b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf082d49-a561-456b-8dde-23614ad752c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Relative Imports\n",
    "package_path = Path(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "sys.path.insert(0, str(package_path))\n",
    "\n",
    "from src.expressive_leaky_memory_neuron_v2 import ELM\n",
    "from src.expressive_leaky_memory_neuron_forget import ELMf\n",
    "from src.neuronio.neuronio_data_utils import (\n",
    "    NEURONIO_DATA_DIM, \n",
    "    NEURONIO_LABEL_DIM, \n",
    "    get_data_files_from_folder, \n",
    "    parse_sim_experiment_file,\n",
    "    visualize_training_batch,\n",
    ")\n",
    "from src.neuronio.neuronio_data_loader_filtered import NeuronIO\n",
    "from src.neuronio.neuronio_train_utils import NeuronioLoss\n",
    "from src.neuronio.neuronio_eval_utils import (\n",
    "    NeuronioEvaluator, \n",
    "    compute_test_predictions_multiple_sim_files, \n",
    "    filter_and_extract_core_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e390e7-f4a9-4669-bbc4-4c0009e0ba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# General Config\n",
    "general_config = dict()\n",
    "general_config[\"seed\"] = 0\n",
    "general_config[\"device\"] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "general_config[\"short_training_run\"] = True # TODO: change to full length run\n",
    "general_config[\"verbose\"] = True #general_config[\"short_training_run\"]\n",
    "torch_device = torch.device(general_config[\"device\"])\n",
    "print(\"Torch Device: \", torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db9cf83-f768-4733-bbb2-37cbec34db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding & Determinism\n",
    "os.environ['PYTHONHASHSEED'] = str(general_config[\"seed\"])\n",
    "random.seed(general_config[\"seed\"])\n",
    "np.random.seed(general_config[\"seed\"])\n",
    "torch.manual_seed(general_config[\"seed\"])\n",
    "torch.cuda.manual_seed(general_config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010efe8-2c3b-4240-81f1-62838f453978",
   "metadata": {},
   "source": [
    "## Data, Model, Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293f1c1f-34af-4e4a-a682-88556adfae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this step requires you having downloaded the dataset\n",
    "\n",
    "# Download Train Data: \n",
    "# https://www.kaggle.com/datasets/selfishgene/single-neurons-as-deep-nets-nmda-train-data\n",
    "# Download Test Data: \n",
    "# https://www.kaggle.com/datasets/selfishgene/single-neurons-as-deep-nets-nmda-test-data # Data_test\n",
    "\n",
    "# Location of downloaded folders\n",
    "data_dir_path = Path(\"D:/NeuronIO\").expanduser().resolve() # TODO: change to neuronio data path\n",
    "train_data_dir_path = data_dir_path / \"train\"  # TODO: change to train subfolder\n",
    "test_data_dir_path = data_dir_path / \"test/Data_test\"  # TODO: change to test subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8b2498-2bfb-4068-9288-e0041a84421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Config\n",
    "\n",
    "data_config = dict()\n",
    "train_data_dirs = [\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_2\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_3\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_4\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_5\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_6\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_7\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_8\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_9\"),\n",
    "    str(train_data_dir_path / \"full_ergodic_train_batch_10\"),\n",
    "]\n",
    "valid_data_dirs = [str(train_data_dir_path / \"full_ergodic_train_batch_1\")]\n",
    "test_data_dirs = [str(test_data_dir_path)]\n",
    "\n",
    "data_config[\"train_data_dirs\"] = train_data_dirs\n",
    "data_config[\"valid_data_dirs\"] = valid_data_dirs\n",
    "data_config[\"test_data_dirs\"] = test_data_dirs\n",
    "\n",
    "data_config[\"data_dim\"] = NEURONIO_DATA_DIM \n",
    "data_config[\"label_dim\"] = NEURONIO_LABEL_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb70a097-7a21-4710-b36a-385c905b227f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Config\n",
    "\n",
    "model_config = dict()\n",
    "model_config[\"num_input\"] = data_config[\"data_dim\"]\n",
    "model_config[\"num_output\"] = data_config[\"label_dim\"]\n",
    "model_config[\"num_memory\"] = 10\n",
    "#model_config[\"mlp_hidden_size\"] = 10\n",
    "model_config[\"memory_tau_max\"] = 150.0\n",
    "model_config[\"num_branch\"] = 45\n",
    "model_config[\"num_synapse_per_branch\"] = 100\n",
    "model_config[\"input_to_synapse_routing\"] = \"neuronio_routing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfccb70-6006-4dea-8e1c-750276e2bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Config\n",
    "\n",
    "train_config = dict()\n",
    "train_config['forget_gate'] = True\n",
    "train_config[\"num_epochs\"] = 5 if general_config[\"short_training_run\"] else 30\n",
    "train_config[\"learning_rate\"] = 5e-4\n",
    "train_config[\"batch_size\"] = 16 if general_config[\"short_training_run\"] else 8\n",
    "train_config[\"batches_per_epoch\"] = 1000 if general_config[\"short_training_run\"] else 5000 #10000\n",
    "train_config[\"batches_per_epoch\"] = int(8/train_config[\"batch_size\"] * train_config[\"batches_per_epoch\"])\n",
    "train_config[\"file_load_fraction\"] = 0.5 if general_config[\"short_training_run\"] else 0.3\n",
    "train_config[\"num_prefetch_batch\"] = 1\n",
    "train_config[\"num_workers\"] = 2 # will make run nondeterministic\n",
    "train_config[\"burn_in_time\"] = 150\n",
    "train_config[\"input_window_size\"] = 500\n",
    "train_config[\"rest_start\"] = False\n",
    "train_config[\"sec_len\"] = 200\n",
    "train_config[\"start_save_path\"] = '../data_processed/NeuronIOstartpoint/'\n",
    "train_config[\"ignore_time_from_start\"] = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6eee3b-a9fb-4b3c-bdd0-f21e266fa07f",
   "metadata": {},
   "source": [
    "## Data, Model, Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a454c766-39b7-4dc6-bf8b-0b0172dd7a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing Data Loaders\n",
    "\n",
    "train_files = get_data_files_from_folder(data_config[\"train_data_dirs\"])\n",
    "valid_files = get_data_files_from_folder(data_config[\"valid_data_dirs\"])\n",
    "test_files = get_data_files_from_folder(data_config[\"test_data_dirs\"])\n",
    "\n",
    "train_data_loader = NeuronIO(\n",
    "    file_paths=train_files,\n",
    "    batches_per_epoch=train_config[\"batches_per_epoch\"],\n",
    "    batch_size=train_config[\"batch_size\"],\n",
    "    input_window_size=train_config[\"input_window_size\"],\n",
    "    num_workers=train_config[\"num_workers\"],\n",
    "    num_prefetch_batch=train_config[\"num_prefetch_batch\"],\n",
    "    file_load_fraction=train_config[\"file_load_fraction\"],\n",
    "    rest_start = train_config[\"rest_start\"],\n",
    "    sec_len = train_config[\"sec_len\"],\n",
    "    save_path = train_config[\"start_save_path\"],\n",
    "    seed=general_config[\"seed\"],\n",
    "    ignore_time_from_start = train_config[\"ignore_time_from_start\"],\n",
    "    device=torch_device,\n",
    ")\n",
    "\n",
    "train_evaluator = NeuronioEvaluator(\n",
    "    test_file=train_files[0],\n",
    "    burn_in_time=train_config[\"burn_in_time\"],\n",
    "    input_window_size=train_config[\"input_window_size\"],\n",
    "    device=torch_device,\n",
    ")\n",
    "\n",
    "valid_evaluator = NeuronioEvaluator(\n",
    "    test_file=valid_files[0],\n",
    "    burn_in_time=train_config[\"burn_in_time\"],\n",
    "    input_window_size=train_config[\"input_window_size\"],\n",
    "    device=torch_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb6d0f1-216d-4bae-b974-a2f03719b20c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_viz, (y_spike_viz, y_soma_viz) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_data_loader\u001b[49m))\n\u001b[0;32m      3\u001b[0m visualize_training_batch(X_viz, y_spike_viz, y_soma_viz, num_viz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize training data\n",
    "X_viz, (y_spike_viz, y_soma_viz) = next(iter(train_data_loader))\n",
    "visualize_training_batch(X_viz, y_spike_viz, y_soma_viz, num_viz=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8de4b45-ed6d-4e80-a93d-ba37924ce29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the ELM model\n",
    "if train_config['forget_gate']:\n",
    "    model = ELMf(**model_config).to(torch_device)\n",
    "else:\n",
    "    model = ELM(**model_config).to(torch_device)\n",
    "\n",
    "# Initialize the loss function, optimizer, and scheduler\n",
    "criterion= NeuronioLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_config[\"learning_rate\"])\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=train_config[\"batches_per_epoch\"] * train_config[\"num_epochs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deff22f-1821-465b-8b7c-5d0714dc0ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize ELM model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60622614-4889-4b44-bc93-613512e71a33",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "520132ff-4b66-4a78-85c6-58097825b2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.09125: 100%|█████████████████████████████████████████████████████████| 500/500 [04:34<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.09125, Train RMSE: 1.81739, Train AUC: 0.71932, Valid RMSE: 1.81899, Valid AUC: 0.72942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.02498: 100%|█████████████████████████████████████████████████████████| 500/500 [04:03<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 0.02498, Train RMSE: 1.54311, Train AUC: 0.95956, Valid RMSE: 1.51724, Valid AUC: 0.96138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.02058: 100%|█████████████████████████████████████████████████████████| 500/500 [03:53<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 0.02058, Train RMSE: 1.46073, Train AUC: 0.96512, Valid RMSE: 1.41557, Valid AUC: 0.96787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.02021: 100%|█████████████████████████████████████████████████████████| 500/500 [03:52<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 0.02021, Train RMSE: 1.43859, Train AUC: 0.96613, Valid RMSE: 1.39075, Valid AUC: 0.96856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.01987: 100%|█████████████████████████████████████████████████████████| 500/500 [03:55<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 0.01987, Train RMSE: 1.43470, Train AUC: 0.96629, Valid RMSE: 1.38508, Valid AUC: 0.96865\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best validation RMSE to a high value\n",
    "best_valid_rmse = float('inf')\n",
    "best_model_state_dict = model.state_dict().copy()\n",
    "\n",
    "# Training loop\n",
    "train_rmse_hist = []\n",
    "train_auc_hist = []\n",
    "valid_rmse_hist = []\n",
    "valid_auc_hist = []\n",
    "for epoch in range(train_config[\"num_epochs\"]):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(\n",
    "        enumerate(train_data_loader, 0),\n",
    "        total=train_config[\"batches_per_epoch\"],\n",
    "        disable=not general_config[\"verbose\"],\n",
    "    )\n",
    "    for i, data in pbar:\n",
    "        inputs, targets = data\n",
    "        \n",
    "        # Perform a single training step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_description(f\"Epoch {epoch+1} Loss: {running_loss / (i+1):.5f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Evaluate on training data\n",
    "        train_eval_metrics = train_evaluator.evaluate(model)\n",
    "        train_rmse = train_eval_metrics[\"soma_RMSE\"]\n",
    "        train_auc = train_eval_metrics[\"AUC\"]\n",
    "        train_rmse_hist.append(train_rmse)\n",
    "        train_auc_hist.append(train_auc)\n",
    "\n",
    "        # Evaluate on validation data\n",
    "        valid_eval_metrics = valid_evaluator.evaluate(model)\n",
    "        valid_rmse = valid_eval_metrics[\"soma_RMSE\"]\n",
    "        valid_auc = valid_eval_metrics[\"AUC\"]\n",
    "        valid_rmse_hist.append(valid_rmse)\n",
    "        valid_auc_hist.append(valid_auc)\n",
    "\n",
    "    # Copy model state dict if validation RMSE has improved\n",
    "    if valid_rmse < best_valid_rmse:\n",
    "        best_valid_rmse = valid_rmse\n",
    "        best_model_state_dict = model.state_dict().copy()\n",
    "\n",
    "    # Print statistics\n",
    "    print(\n",
    "        f'Epoch: {epoch+1}, '\n",
    "        f'Train Loss: {running_loss / train_config[\"batches_per_epoch\"]:.5f}, '\n",
    "        f'Train RMSE: {train_rmse:.5f}, Train AUC: {train_auc:.5f}, '\n",
    "        f'Valid RMSE: {valid_rmse:.5f}, Valid AUC: {valid_auc:.5f}'\n",
    "    )\n",
    "\n",
    "# Free up memory\n",
    "del train_data_loader\n",
    "gc.collect()\n",
    "\n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(best_model_state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86219a09-e3b2-405c-9283-2c8f2aa2fe8c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233c7dc-9ce7-46e4-833d-67b1ab965f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model.neuronio_eval_forward(X_viz)\n",
    "    visualize_training_batch(X_viz, y_spike_viz, y_soma_viz, outputs[..., 0], outputs[..., 1], num_viz=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943527ef-7519-4183-9eef-63c87416e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all evaluation metrics\n",
    "with torch.no_grad():\n",
    "    if not general_config[\"short_training_run\"]:\n",
    "        random.seed(general_config[\"seed\"])\n",
    "        select_train_files = random.choices(train_files, k=10)\n",
    "        train_predictions = compute_test_predictions_multiple_sim_files(\n",
    "            neuron=model,\n",
    "            test_files=select_train_files,\n",
    "            burn_in_time=train_config[\"burn_in_time\"],\n",
    "            input_window_size=train_config[\"input_window_size\"],\n",
    "            device=torch_device,\n",
    "        )\n",
    "        train_results = filter_and_extract_core_results(*train_predictions, verbose=False)\n",
    "\n",
    "        valid_predictions = compute_test_predictions_multiple_sim_files(\n",
    "            neuron=model,\n",
    "            test_files=valid_files,\n",
    "            burn_in_time=train_config[\"burn_in_time\"],\n",
    "            input_window_size=train_config[\"input_window_size\"],\n",
    "            device=torch_device,\n",
    "        )\n",
    "        valid_results = filter_and_extract_core_results(*valid_predictions, verbose=False)\n",
    "\n",
    "    test_predictions = compute_test_predictions_multiple_sim_files(\n",
    "        neuron=model,\n",
    "        test_files=test_files,\n",
    "        burn_in_time=train_config[\"burn_in_time\"],\n",
    "        input_window_size=train_config[\"input_window_size\"],\n",
    "        device=torch_device,\n",
    "    )\n",
    "    test_results = filter_and_extract_core_results(*test_predictions, verbose=False)\n",
    "\n",
    "eval_results = dict()\n",
    "if not general_config[\"short_training_run\"]:\n",
    "    eval_results[\"train_results\"] = train_results\n",
    "    eval_results[\"valid_results\"] = valid_results\n",
    "eval_results[\"test_results\"] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30599ef6-757f-4b16-b141-7628eb9304be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_results': {'TP @ 0.0025 FP': np.float64(0.16651319828115407),\n",
       "  'AUC @ 0.0025 FP': np.float64(0.08920503376304481),\n",
       "  'TP @ 0.0100 FP': np.float64(0.43784530386740333),\n",
       "  'AUC @ 0.0100 FP': np.float64(0.2611127302835369),\n",
       "  'AUC': np.float64(0.9643355718697292),\n",
       "  'soma_explained_variance_percent': 83.82370825049937,\n",
       "  'soma_RMSE': np.float64(1.233571460924803),\n",
       "  'soma_MAE': 0.8693042140735558}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show evaluation results\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6345c-94e8-4070-9c13-f13080225641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
